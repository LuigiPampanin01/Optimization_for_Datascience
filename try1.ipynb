{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f58220d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def grad_x(X, S):\n",
    "\n",
    "    X_inv = np.linalg.inv(X)\n",
    "    return S - X_inv\n",
    "\n",
    "def arg_prox(X, t, grad_x, S):\n",
    "\n",
    "    return X - t * grad_x(X, S)\n",
    "\n",
    "def h_func_cp(X, gamma):\n",
    "    offdiag_mask = ~np.eye(X.shape[0], dtype=bool)\n",
    "    return gamma * cp.norm1(cp.multiply(offdiag_mask, X))\n",
    "\n",
    "def h_func(X, gamma):\n",
    "    offdiag_mask = ~np.eye(X.shape[0], dtype=bool)\n",
    "    return gamma * np.sum(np.abs(np.multiply(offdiag_mask, X)))\n",
    "\n",
    "def prox_h(X, h_func_cp, t, grad_x, arg_prox, S, gamma):\n",
    "    \"\"\"\n",
    "    Compute prox_{h}(x) = argmin_y h(y) + 0.5 * ||y - x||_2^2\n",
    "\n",
    "    Parameters:\n",
    "    - x (np.ndarray): The point at which to evaluate the proximal operator\n",
    "    - h_func_cp (callable): A function that accepts a cvxpy Variable y and returns h(y)\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Result of the proximal operator\n",
    "    \"\"\"\n",
    "    x = arg_prox(X, t, grad_x, S)\n",
    "\n",
    "    y = cp.Variable(x.shape)\n",
    "    objective = h_func_cp(y, gamma) + 0.5 * cp.sum_squares(y - x)\n",
    "    problem = cp.Problem(cp.Minimize(objective))\n",
    "    problem.solve()\n",
    "    return y.value\n",
    "\n",
    "\n",
    "\n",
    "def compute_U(X, S, gamma):\n",
    "    \"\"\"\n",
    "    Compute U where:\n",
    "    U_ij = max(-gamma, min(gamma, [X_inv - S]_ij)) for i ≠ j\n",
    "           0 for i == j\n",
    "    \n",
    "    Parameters:\n",
    "    - X (np.ndarray): Square positive definite matrix\n",
    "    - S (np.ndarray): Symmetric matrix of same shape as X\n",
    "    - gamma (float): Threshold parameter\n",
    "    \n",
    "    Returns:\n",
    "    - np.ndarray: Matrix U\n",
    "    \"\"\"\n",
    "    X_inv = np.linalg.inv(X)\n",
    "    diff = X_inv - S\n",
    "\n",
    "    # Apply soft thresholding only to off-diagonal elements\n",
    "    U = np.zeros_like(diff)\n",
    "    for i in range(diff.shape[0]):\n",
    "        for j in range(diff.shape[1]):\n",
    "            if i != j:\n",
    "                U[i, j] = np.clip(diff[i, j], -gamma, gamma)\n",
    "            else:\n",
    "                U[i, j] = 0  # optional, since we initialized with zeros\n",
    "\n",
    "    return U\n",
    "\n",
    "def g_func(X, S):\n",
    "    return np.trace(S @ X) + np.log(np.linalg.det(X))\n",
    "\n",
    "def compute_stopping_criterion(X, S, g_func, h_func, gamma, compute_U):\n",
    "\n",
    "    n = X.shape[0]\n",
    "\n",
    "    delta = g_func(X, S) + h_func(X, gamma) - np.log(np.linalg.det(S + compute_U(X, S, gamma))) - n\n",
    "    \n",
    "    return delta\n",
    "\n",
    "def proximal_gradient_descend(X, h_func_cp, h_func, t, grad_x, arg_prox, S, gamma, g_func, compute_U, epsilon=1e-2): # TODO : i'm not fucking sure this work, can you guys check please \n",
    "\n",
    "    while True:\n",
    "        X_new = prox_h(X, h_func_cp, t, grad_x, arg_prox, S, gamma)\n",
    "        delta = compute_stopping_criterion(X_new, S, g_func, h_func, gamma, compute_U)\n",
    "\n",
    "        X = X_new\n",
    "\n",
    "        if delta <= epsilon:\n",
    "            break \n",
    "    \n",
    "    return X\n",
    "\n",
    "def backtracking_line_search(phi, phi_derivative_at_0, t_init, alpha1=0.1, beta=0.7):\n",
    "    \"\"\"\n",
    "    Perform backtracking line search to find step size t.\n",
    "\n",
    "    Parameters:\n",
    "        phi (function): A continuously differentiable function φ: R → R.\n",
    "        phi_derivative_at_0 (float): The derivative φ'(0).\n",
    "        t_init (float): Initial step size (t >= 0).\n",
    "        alpha1 (float): Parameter in (0, 0.5], default 0.1.\n",
    "        beta (float): Parameter in (0, 1), default 0.7.\n",
    "\n",
    "    Returns:\n",
    "        float: Step size t such that φ(t) ≤ φ(0) + α1 * t * φ'(0)\n",
    "    \"\"\"\n",
    "    t = t_init\n",
    "    phi_0 = phi(0)\n",
    "\n",
    "    while phi(t) > phi_0 + alpha1 * t * phi_derivative_at_0:\n",
    "        t *= beta\n",
    "\n",
    "    return t\n",
    "\n",
    "def proximal_gradient_descend(X, h_func_cp, h_func, t_init, grad_x, arg_prox, S, gamma, g_func, compute_U, epsilon=1e-2):\n",
    "\n",
    "    while True:\n",
    "        grad = grad_x(X, S)\n",
    "\n",
    "        def phi(t):\n",
    "            X_temp = prox_h(X, h_func_cp, t, grad_x, arg_prox, S, gamma)\n",
    "            return g_func(X_temp, S) + h_func(X_temp, gamma)\n",
    "\n",
    "        phi_derivative_at_0 = np.sum(grad * (-grad))  # directional derivative: <∇g, -∇g>\n",
    "\n",
    "        t = backtracking_line_search(phi, phi_derivative_at_0, t_init)\n",
    "\n",
    "        X_new = prox_h(X, h_func_cp, t, grad_x, arg_prox, S, gamma)\n",
    "        delta = compute_stopping_criterion(X_new, S, g_func, h_func, gamma, compute_U)\n",
    "\n",
    "        X = X_new\n",
    "\n",
    "        if delta <= epsilon:\n",
    "            break\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40e28862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q1/rqglfbqj20db36k7w1n5qxbc0000gn/T/ipykernel_7392/3877920705.py:74: RuntimeWarning: invalid value encountered in log\n",
      "  return np.trace(S @ X) + np.log(np.linalg.det(X))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m      7\u001b[0m t_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m----> 9\u001b[0m X_result \u001b[38;5;241m=\u001b[39m proximal_gradient_descend(X_init, h_func_cp, h_func, t_init, grad_x, arg_prox, S, gamma, g_func, compute_U)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal X:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, X_result)\n",
      "Cell \u001b[0;32mIn[1], line 130\u001b[0m, in \u001b[0;36mproximal_gradient_descend\u001b[0;34m(X, h_func_cp, h_func, t_init, grad_x, arg_prox, S, gamma, g_func, compute_U, epsilon)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m g_func(X_temp, S) \u001b[38;5;241m+\u001b[39m h_func(X_temp, gamma)\n\u001b[1;32m    128\u001b[0m phi_derivative_at_0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(grad \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39mgrad))  \u001b[38;5;66;03m# directional derivative: <∇g, -∇g>\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m t \u001b[38;5;241m=\u001b[39m backtracking_line_search(phi, phi_derivative_at_0, t_init)\n\u001b[1;32m    132\u001b[0m X_new \u001b[38;5;241m=\u001b[39m prox_h(X, h_func_cp, t, grad_x, arg_prox, S, gamma)\n\u001b[1;32m    133\u001b[0m delta \u001b[38;5;241m=\u001b[39m compute_stopping_criterion(X_new, S, g_func, h_func, gamma, compute_U)\n",
      "Cell \u001b[0;32mIn[1], line 112\u001b[0m, in \u001b[0;36mbacktracking_line_search\u001b[0;34m(phi, phi_derivative_at_0, t_init, alpha1, beta)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03mPerform backtracking line search to find step size t.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    float: Step size t such that φ(t) ≤ φ(0) + α1 * t * φ'(0)\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m t \u001b[38;5;241m=\u001b[39m t_init\n\u001b[0;32m--> 112\u001b[0m phi_0 \u001b[38;5;241m=\u001b[39m phi(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m phi(t) \u001b[38;5;241m>\u001b[39m phi_0 \u001b[38;5;241m+\u001b[39m alpha1 \u001b[38;5;241m*\u001b[39m t \u001b[38;5;241m*\u001b[39m phi_derivative_at_0:\n\u001b[1;32m    115\u001b[0m     t \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m beta\n",
      "Cell \u001b[0;32mIn[1], line 126\u001b[0m, in \u001b[0;36mproximal_gradient_descend.<locals>.phi\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mphi\u001b[39m(t):\n\u001b[1;32m    125\u001b[0m     X_temp \u001b[38;5;241m=\u001b[39m prox_h(X, h_func_cp, t, grad_x, arg_prox, S, gamma)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m g_func(X_temp, S) \u001b[38;5;241m+\u001b[39m h_func(X_temp, gamma)\n",
      "Cell \u001b[0;32mIn[1], line 73\u001b[0m, in \u001b[0;36mg_func\u001b[0;34m(X, S)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 U[i, j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# optional, since we initialized with zeros\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m U\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mg_func\u001b[39m(X, S):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mtrace(S \u001b[38;5;241m@\u001b[39m X) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mdet(X))\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_stopping_criterion\u001b[39m(X, S, g_func, h_func, gamma, compute_U):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "n = 3\n",
    "A = np.random.randn(n, n)\n",
    "S = A @ A.T  # make S symmetric positive definite\n",
    "X_init = np.eye(n)\n",
    "gamma = 0.1\n",
    "t_init = 1.0\n",
    "\n",
    "X_result = proximal_gradient_descend(X_init, h_func_cp, h_func, t_init, grad_x, arg_prox, S, gamma, g_func, compute_U)\n",
    "print(\"Final X:\\n\", X_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ml_sp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
